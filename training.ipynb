{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  | Name     | Type               | Params\n",
      "------------------------------------------------\n",
      "0 | model    | ResNet             | 11.2 M\n",
      "1 | accuracy | MulticlassAccuracy | 0     \n",
      "------------------------------------------------\n",
      "11.2 M    Trainable params\n",
      "0         Non-trainable params\n",
      "11.2 M    Total params\n",
      "44.710    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 10/10 [00:06<00:00,  1.64it/s, v_num=1, train_acc=1.000, val_acc=1.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=25` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 10/10 [00:06<00:00,  1.56it/s, v_num=1, train_acc=1.000, val_acc=1.000]\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from PIL import Image\n",
    "from sklearn.metrics import accuracy_score\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.models as models\n",
    "from torchmetrics import Accuracy\n",
    "import pytorch_lightning as pl\n",
    "\n",
    "# Set paths for data\n",
    "CHICKEN_IMAGES_PATH = \"data/chicken-images/data\"\n",
    "DUCK_IMAGES_PATH = \"data/duck-images/data\"\n",
    "\n",
    "# Create annotations for datasets\n",
    "def create_annotations_file(paths):\n",
    "    datasets = {'train': [], 'val': [], 'test': []}\n",
    "    for phase in ['train', 'val', 'test']:\n",
    "        for path in paths:\n",
    "            full_path = os.path.join(path, phase)\n",
    "            image_names = [os.path.join(full_path, img_name) for img_name in os.listdir(full_path)[:100]]\n",
    "            label = path.split(\"/\")[-2]\n",
    "            datasets[phase].extend([(img, label) for img in image_names])\n",
    "    \n",
    "    return {x: pd.DataFrame(datasets[x], columns=[\"path\", \"class\"]) for x in datasets}\n",
    "\n",
    "# Load datasets\n",
    "datasets = create_annotations_file([CHICKEN_IMAGES_PATH, DUCK_IMAGES_PATH])\n",
    "train, val, test = datasets['train'], datasets['val'], datasets['test']\n",
    "\n",
    "# Dataset class\n",
    "class ChickenOrDuck(Dataset):\n",
    "    def __init__(self, annotations_file, transform=None):\n",
    "        self.annotations_file = annotations_file\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.annotations_file)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path, img_label = self.annotations_file.iloc[idx]\n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        label = 1 if img_label == 'chicken' else 0\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, label\n",
    "\n",
    "# Transformations for image processing\n",
    "transformations = {\n",
    "    'train': transforms.Compose([\n",
    "        transforms.Resize((128, 128)),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ColorJitter(brightness=0.2, contrast=0.2),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ]),\n",
    "    'val': transforms.Compose([\n",
    "        transforms.Resize((128, 128)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "}\n",
    "\n",
    "# Datasets and Dataloaders\n",
    "train_dataset = ChickenOrDuck(train, transformations['train'])\n",
    "val_dataset = ChickenOrDuck(val, transformations['val'])\n",
    "test_dataset = ChickenOrDuck(test, transformations['val'])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=20, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=20)\n",
    "\n",
    "# Define a Lightning Module for training\n",
    "class ImageClassifier(pl.LightningModule):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        backbone = models.resnet18(pretrained=True)\n",
    "        num_ftrs = backbone.fc.in_features\n",
    "        backbone.fc = nn.Linear(num_ftrs, 2)\n",
    "        self.model = backbone\n",
    "        self.accuracy = Accuracy(task='multiclass', num_classes=2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.model(x)\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = F.cross_entropy(y_hat, y)\n",
    "        acc = self.accuracy(y_hat.softmax(dim=-1), y)\n",
    "        self.log('train_loss', loss)\n",
    "        self.log('train_acc', acc, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        x, y = batch\n",
    "        y_hat = self(x)\n",
    "        loss = F.cross_entropy(y_hat, y)\n",
    "        acc = self.accuracy(y_hat.softmax(dim=-1), y)\n",
    "        self.log('val_loss', loss)\n",
    "        self.log('val_acc', acc, prog_bar=True)\n",
    "        return loss\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        return optim.Adam(self.model.parameters(), lr=2e-3)\n",
    "\n",
    "# Training the model\n",
    "trainer = pl.Trainer(max_epochs=25)\n",
    "model = ImageClassifier()\n",
    "trainer.fit(model, train_loader, val_loader)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
